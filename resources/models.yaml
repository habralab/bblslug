---
# -------------------------------------------------------------------
# Anthropic (Claude)
# -------------------------------------------------------------------
anthropic:
  endpoint: 'https://api.anthropic.com/v1/chat/completions'
  format: text
  defaults:
    temperature: 0.0
    source_lang: auto
    target_lang: EN
  requirements:
    auth:
      type: header
      key_name: x-api-key
      env: ANTHROPIC_API_KEY
      help_url: 'https://console.anthropic.com/'
    headers:
      - 'Content-Type: application/json'
      - 'Anthropic-Version: 2023-06-01'
  limits:
    estimated_max_chars: 400000
  http_error_handling: true
  usage:
    tokens:
      total: total_tokens
      breakdown:
        prompt: prompt_tokens
        completion: completion_tokens

  models:
    claude-haiku-3.5:
      defaults:
        model: claude-3-5-haiku-latest
        max_tokens: 8192
      notes: 'A lightweight, low-latency model ideal for simple and quick translation tasks.'

    claude-opus-4:
      defaults:
        model: claude-opus-4-20250514
        max_tokens: 32000
      limits:
        estimated_max_chars: 800000
      notes: 'The most capable Claude model, with the largest context window.'

    claude-sonnet-4:
      defaults:
        model: claude-sonnet-4-20250514
        max_tokens: 64000
      limits:
        estimated_max_chars: 800000
      notes: 'A balanced model offering strong quality with lower latency and cost compared to Opus.'


# -------------------------------------------------------------------
# DeepL
# -------------------------------------------------------------------
deepl:
  endpoint: 'https://api-free.deepl.com/v2/translate'
  format: text|html
  defaults:
    target_lang: EN
    formality: prefer_more
  requirements:
    auth:
      type: form
      key_name: auth_key
      help_url: 'https://www.deepl.com/account/summary'
    headers:
      - 'Content-Type: application/x-www-form-urlencoded'
    body_type: form
    params:
      - text
      - target_lang
  limits:
    estimated_max_chars: 30000

  models:
    free:
      name: 'DeepL API Free'
      requirements:
        auth:
          env: DEEPL_FREE_API_KEY
      notes: 'Best for structured HTML or plain text, with a limited monthly quota (free tier).'

    pro:
      name: 'DeepL API Pro'
      requirements:
        auth:
          env: DEEPL_PRO_API_KEY
      notes: 'Reliable structured translation for production use, requires paid subscription.'


# -------------------------------------------------------------------
# Google Gemini
# -------------------------------------------------------------------
google:
  format: text
  defaults:
    temperature: 0.0
    candidateCount: 1
    maxOutputTokens: null
  requirements:
    auth:
      type: header
      key_name: x-goog-api-key
      env: GOOGLE_API_KEY
      help_url: 'https://makersuite.google.com/app/apikey'
    headers:
      - 'Content-Type: application/json'
    body_type: json
    params:
      - system_instruction
      - contents
      - generationConfig
  usage:
    tokens:
      total: totalTokenCount
      breakdown:
        prompt: promptTokenCount
        candidates: candidatesTokenCount
        thoughts: thoughtsTokenCount

  models:
    gemini-2.5-flash:
      name: 'Gemini 2.5 Flash'
      endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent'
      defaults:
        model: gemini-2.5-flash
        thinkingBudget: null
        includeThoughts: null
      limits:
        max_tokens: 131072
        token_estimator: gpt
        estimated_max_chars: 524288
      notes: 'High-performance Flash model with chain-of-thought support.'

    gemini-2.5-flash-lite:
      name: 'Gemini 2.5 Flash-Lite'
      endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent'
      defaults:
        model: gemini-2.5-flash-lite
        thinkingBudget: null
        includeThoughts: null
      limits:
        max_tokens: 131072
        token_estimator: gpt
        estimated_max_chars: 524288
      notes: 'Ultra-fast, cost-optimized Flash-Lite variant.'

    gemini-2.5-pro:
      name: 'Gemini 2.5 Pro'
      endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent'
      defaults:
        model: gemini-2.5-pro
        thinkingBudget: null
        includeThoughts: null
      limits:
        max_tokens: 262144
        token_estimator: gpt
        estimated_max_chars: 1048576
      notes: 'Top-tier Pro model for longest contexts and highest accuracy.'

    gemini-2.0-flash:
      name: 'Gemini 2.0 Flash'
      endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent'
      defaults:
        model: gemini-2.0-flash
      limits:
        max_tokens: 131072
        token_estimator: gpt
        estimated_max_chars: 524288
      notes: 'Low-latency Flash model, balanced cost and performance.'


# -------------------------------------------------------------------
# OpenAI GPT
# -------------------------------------------------------------------
openai:
  endpoint: 'https://api.openai.com/v1/chat/completions'
  defaults:
    temperature: 0.0
  requirements:
    auth:
      type: header
      key_name: Authorization
      prefix: Bearer
      env: OPENAI_API_KEY
      help_url: 'https://platform.openai.com/account/api-keys'
    headers:
      - 'Content-Type: application/json'
  limits:
    token_estimator: gpt
  usage:
    tokens:
      total: total_tokens
      breakdown:
        prompt: prompt_tokens
        completion: completion_tokens
        reasoning: completion_tokens_details.reasoning_tokens

  models:
    gpt-5:
      name: 'OpenAI GPT-5'
      defaults:
        model: gpt-5
        temperature: 1
      limits:
        max_tokens: 400000
        max_output_tokens: 128000
        estimated_max_chars: 1600000   # 400k * 4
      notes: 'Flagship model with enhanced reasoning, multimodal capabilities, and extended context support.'

    gpt-5-mini:
      name: 'OpenAI GPT-5 Mini'
      defaults:
        model: gpt-5-mini
        temperature: 1
      limits:
        max_tokens: 400000
        max_output_tokens: 128000
        estimated_max_chars: 1600000
      notes: 'Compact, cost-efficient GPT-5 variant suitable for high-volume or latency-sensitive translation tasks.'

    gpt-5-nano:
      name: 'OpenAI GPT-5 Nano'
      defaults:
        model: gpt-5-nano
        temperature: 1
      limits:
        max_tokens: 400000
        max_output_tokens: 128000
        estimated_max_chars: 1600000
      notes: 'Ultra-fast GPT-5 variant optimized for small-scale and real-time translation tasks.'

    gpt-4o:
      name: 'OpenAI GPT-4o'
      defaults:
        model: gpt-4o
      limits:
        max_tokens: 128000
        max_output_tokens: 16384
        estimated_max_chars: 512000
      notes: 'Highly accurate with flexible prompts, ideal for AI-assisted adaptive translation.'

    gpt-4o-mini:
      name: 'OpenAI GPT-4o Mini'
      defaults:
        model: gpt-4o-mini
      limits:
        max_tokens: 128000
        max_output_tokens: 16384
        estimated_max_chars: 512000
      notes: 'Lightweight GPT-4o: lower latency/cost.'

    gpt-4:
      name: 'OpenAI GPT-4'
      defaults:
        model: gpt-4
      limits:
        max_tokens: 8192
        estimated_max_chars: 32768
      notes: 'Classic GPT-4 model: highest reliability.'

    gpt-4-turbo:
      name: 'OpenAI GPT-4 Turbo'
      defaults:
        model: gpt-4-turbo
      limits:
        max_tokens: 128000
        estimated_max_chars: 512000
      notes: 'Fast & cost-effective GPT-4 quality.'


# -------------------------------------------------------------------
# Yandex Foundation Models
# -------------------------------------------------------------------
yandex:
  endpoint: 'https://llm.api.cloud.yandex.net/foundationModels/v1/completion'
  format: text
  defaults:
    temperature: 0.0
    max_tokens: 8192
  requirements:
    auth:
      help_url: 'https://yandex.cloud/en/docs/foundation-models/api-ref/authentication'
      type: header
      key_name: Authorization
      prefix: Bearer
      env: YANDEX_API_KEY
    variables:
      folder_id: YANDEX_FOLDER_ID
    headers:
      - 'Content-Type: application/json'
  limits:
    max_tokens: 8192
    token_estimator: gpt
    estimated_max_chars: 32768
  http_error_handling: true
  usage:
    tokens:
      total: totalTokens
      breakdown:
        input: inputTextTokens
        completion: completionTokens

  models:
    gpt-lite:
      name: 'Yandex GPT Lite'
      defaults:
        model: yandexgpt-lite/latest
      notes: 'Low-latency model with up to 8 k tokens sync or 32 k async.'

    gpt-pro:
      name: 'Yandex GPT Pro'
      defaults:
        model: yandexgpt/latest
      notes: 'High-capacity 5th-gen model, up to 8 k tokens sync or 32 k async.'

    gpt-32k:
      name: 'Yandex GPT Pro 32K'
      defaults:
        model: yandexgpt-32k/latest
        max_tokens: 32000
      limits:
        max_tokens: 32000
        estimated_max_chars: 128000
      notes: 'Extended-context model: up to 32 k tokens (sync only).'

    llama-lite:
      name: 'Llama 8 B (Lite)'
      defaults:
        model: llama-lite/latest
      notes: 'Meta Llama 8 B variant, up to 8 k tokens sync or async.'

    llama:
      name: 'Llama 70 B'
      defaults:
        model: llama/latest
      notes: 'Full-scale Meta Llama 70 B, up to 8 k tokens sync or async.'


# -------------------------------------------------------------------
# xAI (Grok)
# -------------------------------------------------------------------
xai:
  endpoint: 'https://api.x.ai/v1/chat/completions'
  format: text
  defaults:
    temperature: 0.0
    source_lang: auto
    target_lang: EN
  requirements:
    auth:
      type: header
      key_name: Authorization
      prefix: Bearer
      env: XAI_API_KEY
      help_url: 'https://console.x.ai/team/default/api-keys'
    headers:
      - 'Content-Type: application/json'
  limits:
    token_estimator: gpt
  usage:
    tokens:
      total: total_tokens
      breakdown:
        prompt: prompt_tokens
        completion: completion_tokens
        reasoning: completion_tokens_details.reasoning_tokens

  models:
    grok-4:
      name: 'Grok 4'
      defaults:
        model: grok-4
      limits:
        max_tokens: 256000
        estimated_max_chars: 1024000
      notes: 'Scientist-grade reasoning, coding mode, and real-time internet understanding'

    grok-3:
      name: 'Grok 3'
      defaults:
        model: grok-3
      limits:
        max_tokens: 131072
        estimated_max_chars: 524288
      notes: 'Optimized for logical reasoning, math problem-solving, and real-time data with DeepSearch'

    grok-3-mini:
      name: 'Grok 3 Mini'
      defaults:
        model: grok-3-mini
      limits:
        max_tokens: 131072
        estimated_max_chars: 524288
      notes: 'Compact variant balancing Grok 3 performance and efficiency'
